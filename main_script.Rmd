---
title: "(C)-Los diez mejores-7"
author: "Jeorge Atherton & Paulina Castillo"
date: "`r Sys.Date()`"
output: pdf_document
---

---- DELETE ----
Git Reference 
    git init
    git add .
    git commit -m "Add existing project files to Git"
    git remote add origin https://github.com/cameronmcnz/example-website.git
    git push -u -f origin master


```{r, results="hide", message=FALSE, echo=F}
## load/install packages
packages = c("caret","car","mice", "knitr","tidyverse", "GGally")
lapply(packages, require, character.only = TRUE)
options(digits=3)
options(scipen=99)
theme_set(theme_bw())
```


# ---- Data Understanding ----


```{r, message=FALSE, echo=F}
## load data
raw_data = read_csv('Train/Train.csv',show_col_types = FALSE)
str(raw_data, give.attr = FALSE)
```

Redefine datatypes:
```{r, echo=F}

chr_vars = c('sessionId', 'custId', 'keyword', 'referralPath', 'adContent',
             'adwordsClickInfo.gclId', 'networkDomain')

num_vars = c('visitNumber',
'timeSinceLastVisit',
'pageviews','revenue')

log_vars = c('isMobile',
'isTrueDirect', 'adwordsClickInfo.isVideoAd',
'bounces', 'newVisits','adwordsClickInfo.adNetworkType')

date_vars = c('date','visitStartTime')

factor_vars = setdiff(names(raw_data), c(chr_vars,num_vars,log_vars,date_vars))

raw_data_typed = raw_data %>%
  mutate_at(chr_vars, as.character) %>%
  mutate_at(num_vars, as.numeric) %>%
  mutate_at(log_vars, as.logical) %>%
  mutate_at(date_vars, as.Date) %>%
  mutate_at(factor_vars, as_factor) 

raw_data_typed %>% 
  summarise_all(class) %>% 
  gather()
```

Numeric Data Quality Report:
```{r, echo=F}
## helper functions
Q1<-function(x,na.rm=TRUE) {
quantile(x,na.rm=na.rm)[2]
}
Q3<-function(x,na.rm=TRUE) {
quantile(x,na.rm=na.rm)[4]
}

## -- Numeric Summary -- ##
myNumericSummary <- function(x){
c(length(x), 
  n_distinct(x), 
  sum(is.na(x)), 
  mean(x, na.rm=TRUE),
  min(x,na.rm=TRUE), 
  Q1(x,na.rm=TRUE),
  median(x,na.rm=TRUE),
  Q3(x,na.rm=TRUE),
  max(x,na.rm=TRUE), 
  sd(x,na.rm=TRUE))}

numericSummary = raw_data_typed %>%
  select(where(is.numeric)) %>%
  reframe(across(everything(), ~ myNumericSummary(.), .names = "{col}"))

numericSummary = cbind(
stat=c("n","unique","missing","mean","min","Q1","median","Q3","max","sd"),
numericSummary)

#glimpse(numericSummary)

numericSummaryFinal = numericSummary %>%
pivot_longer(-stat, names_to = "variable", values_to = "value") %>%
pivot_wider(names_from = stat, values_from = value) %>%
mutate(missing_pct = 100*missing/n, unique_pct = 100*unique/n) %>%
select(variable, n, missing, missing_pct, unique, unique_pct, everything())

numericSummaryFinal %>% kable()
```
For the numeric variables, it looks like the there aren't many issues with 
missing values but there are definitely some outliers to look out for here. 


Factor Data Quality Report:
```{r, echo=F}
## helper functions
getmodes <- function(v, type = 1) {
  tbl <- table(v)
  m1 <- which.max(tbl)
  if (type == 1) {
    return(names(m1))  # 1st mode
  } else if (type == 2) {
    return(names(which.max(tbl[-m1])))  # 2nd mode
  } else if (type == -1) {
    return(names(which.min(tbl)))  # least common mode
  } else {
    stop("Invalid type selected")
  }
}

getmodesCnt <- function(v, type = 1) {
  tbl <- table(v)
  m1 <- which.max(tbl)
  if (type == 1) {
    return(max(tbl))  # 1st mode frequency
  } else if (type == 2) {
    return(max(tbl[-m1]))  # 2nd mode frequency
  } else if (type == -1) {
    return(min(tbl))  # least common frequency
  } else {
    stop("Invalid type selected")
  }
}

## issue is in this function here...
noNumericSummary <- function(x){
c(length(x), 
  n_distinct(x), 
  sum(is.na(x)), 
  getmodes(x, type=1), # 1st mode
  getmodesCnt(x,type=1), # 1st freq
  getmodes(x, type=2), # 2nd mode
  getmodesCnt(x,type=2), # 2nd freq
  getmodes(x, type=-1), # Less common
  getmodesCnt(x,type=-1) # Less common freq
  )
}

factorSummary = raw_data_typed %>%
  select(where(is.factor)) %>%
  reframe(across(everything(), ~ noNumericSummary(.), .names = "{col}"))

nonumericSummary = cbind(
stat=c("n","unique","missing","1st mode","1st mode freq","2nd mode",
       "2nd mode freq","least common","least common freq"),
factorSummary)

nonumericSummaryFinal <- nonumericSummary %>%
pivot_longer(-stat, names_to = "variable", values_to = "value") %>%
pivot_wider(names_from = stat, values_from = value) %>%
mutate(missing = as.numeric(missing),
         unique = as.numeric(unique),
         n = as.numeric(n)) %>%
mutate(missing_pct = 100*(missing/n),
unique_pct = 100*(unique/n)) %>%
select(variable, n, missing, missing_pct, unique, unique_pct, everything())

nonumericSummaryFinal %>% kable()
```
For factor data we can see a fair number of variables with large proportions 
of missing values. These will likely need to be dropped or handled as being 
another category in the data. It's possible that some of these sparse fields
do a good job of explaining revenue. 


###########################
Let's view some plots now:

```{r, echo=F}
raw_data_typed %>%
  select_if(is.numeric) %>%
  ggcorr() 
```
Definitely some extreme behavior here. Pageviews seems mildly correlated with
revenue but the others we can't tell at the transactional level.

How many customers actually bought anything?
```{r, echo=F}
raw_data_typed %>%
  group_by(custId) %>%
  summarize(bought = ifelse(sum(revenue)>0,1,0)) %>%
  ungroup() %>%
  summarize(mean(bought))
```
Looks like ~11% of customers actually ever bought anything...

Of those customers that bought anything, how much did they spend?
```{r, echo=F}
## of those customers that bought, what does that look like?
raw_data_typed %>%
  group_by(custId) %>%
  summarize(revenue = sum(revenue)) %>%
  filter(revenue>0)  %>%
  ggplot(aes(log(revenue))) +
  geom_histogram(bins=30) +
  labs(title="Natural Log Revenue for Customers that Bought")
```
So essentially the log-adjusted revenue is normal looking. There are now two big
facts: only about 1 in 10 customers actually ever buys anything, but those 
customers that do buy something follows a log adjusted normal distribution. Now
the question is which factors will predict a customer will buy anything at all?

Boxplots of 'bought' by continent:
```{r, echo=F}
raw_data_typed %>%
  group_by(continent,custId) %>%
  summarize(bought = ifelse(sum(revenue)>0,1,0)) %>%
  group_by(continent) %>%
  summarize(bought = mean(bought)) %>%
  ggplot(aes(x=continent, y=bought)) +
  geom_col() +
  scale_y_continuous(limits = c(0,0.50)) +
  labs(title="Proportion of Customers that Bought by Continent")
```
From this simple bar chart, we see clearly that people from the Americas are far 
more likely to buy something over the course of the year than from other 
continents. 


# ---- Data Preparation & Feature Engineering ----


Cast NAs in factors as extra level to preserve information & drop cases of
no page views. There are only 8 cases of no pageviews and they didn't 
buy anything.
```{r, echo=F}
data_clean = raw_data_typed %>%
  mutate_if(is.factor, fct_na_value_to_level) %>%
  filter(!is.na(pageviews))
```

Collapse high cardinality factors, weighted based on revenue. Remove redundant
geographic features. 
```{r, echo=F}
## strategy->collapse factors based on proportion of revenue so most important
## levels are preserved
data_clean = data_clean %>% 
  select(!c("continent", "subContinent", "city", "metro", "region")) %>%
  mutate(browser=fct_lump_n(browser, w=revenue, n=4),
         operatingSystem=fct_lump_n(operatingSystem, w=revenue, n=5),
         source=fct_lump_lowfreq(source, w=revenue),
         country=fct_lump_n(country, n=14),
         topLevelDomain=fct_lump(topLevelDomain, w=revenue, n=4)) 
data_clean %>% str()
```




# ---- EXTRA CODE ---- 

```{r, echo=F}
cols_to_keep = c('date','channelGrouping','visitStartTime','visitNumber',
'timeSinceLastVisit','browser','operatingSystem','isMobile','deviceCategory',
'continent','country','campaign','source','medium','isTrueDirect',
'adwordsClickInfo.slot','pageviews','bounces','revenue')

clean_data = raw_data_typed %>%
  select(all_of(cols_to_keep)) %>%
  mutate(month = factor(month(date)))

```


# ----- PAULINA SOME EXPERIMENTS --------




```{r}
raw_data <- raw_data %>%
  mutate(newVisits = replace_na(newVisits, 0))

```

```{r}
newVisits_summary <- raw_data %>%
  group_by(newVisits) %>%
  summarise(count = n())

# Print the summary of newVisits
print(newVisits_summary)
```



```{r}

# Calculating the 95% Confidence Interval for revenue
mean_revenue <- mean(raw_data$revenue, na.rm = TRUE)
std_error <- sd(raw_data$revenue, na.rm = TRUE) / sqrt(nrow(raw_data))

# 95% confidence interval calculation
ci_lower <- mean_revenue - qt(0.975, df = nrow(raw_data) - 1) * std_error
ci_upper <- mean_revenue + qt(0.975, df = nrow(raw_data) - 1) * std_error

# Display the confidence interval
cat("95% Confidence Interval for Revenue: [", ci_lower, ",", ci_upper, "]\n")
```

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)


# Filter data to exclude missing values in revenue and newVisits
data_new_visit <- raw_data %>% filter(!is.na(revenue), !is.na(newVisits))

# Separate data into two groups: first-time visitors and repeat visitors
first_time_visitors <- data_new_visit %>% filter(newVisits == 1)
repeat_visitors <- data_new_visit %>% filter(newVisits == 0)

```


```{r}
# Function to calculate 95% confidence interval for a given dataset
calc_confidence_interval <- function(data) {
  mean_revenue <- mean(data$revenue, na.rm = TRUE)
  std_error <- sd(data$revenue, na.rm = TRUE) / sqrt(nrow(data))
  
  ci_lower <- mean_revenue - qt(0.975, df = nrow(data) - 1) * std_error
  ci_upper <- mean_revenue + qt(0.975, df = nrow(data) - 1) * std_error
  
  return(c(ci_lower, ci_upper, mean_revenue))
}

# Calculate 95% confidence intervals for both groups
ci_first_time <- calc_confidence_interval(first_time_visitors)
ci_repeat <- calc_confidence_interval(repeat_visitors)

# Print confidence intervals
cat("95% Confidence Interval for First-Time Visitors Revenue: [", ci_first_time[1], ",", ci_first_time[2], "] with a mean of ", ci_first_time[3],"\n")
cat("95% Confidence Interval for Repeat Visitors Revenue: [", ci_repeat[1], ",", ci_repeat[2], "] with a mean of ",ci_repeat[3])

```

There's a difference between who's a new clients who's not 

```{r}

# Group by customer ID and calculate total visits per customer
visit_frequency <- raw_data %>%
  group_by(custId) %>%
  summarise(total_visits = n())

# Visualize the distribution of visit frequency
ggplot(visit_frequency, aes(x = total_visits)) +
  geom_histogram(binwidth = 1, fill = "blue", alpha = 0.7, color = "black") +
  labs(title = "Customer Visit Frequency", x = "Total Visits", y = "Number of Customers") +
  theme_minimal()

```

```{r}
# Device usage by customers
device_usage <- raw_data %>%
  group_by(deviceCategory) %>%
  summarise(count = n())

# Plot device usage
ggplot(device_usage, aes(x = deviceCategory, y = count, fill = deviceCategory)) +
  geom_bar(stat = "identity") +
  labs(title = "Device Usage by Customers", x = "Device Category", y = "Number of Sessions") +
  theme_minimal()

```
```{r}
# Geographic distribution (example by continent)
geo_distribution <- raw_data %>%
  group_by(continent) %>%
  summarise(count = n())

# Plot geographic distribution
ggplot(geo_distribution, aes(x = continent, y = count, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Geographic Distribution of Customers", x = "Continent", y = "Number of Sessions") +
  theme_minimal()

```
```{r}
# Analyze average pageviews per customer session
session_activity <- raw_data %>%
  group_by(custId) %>%
  summarise(avg_pageviews = mean(pageviews, na.rm = TRUE))

# Plot average pageviews
ggplot(session_activity, aes(x = avg_pageviews)) +
  geom_histogram(binwidth = 1, fill = "green", alpha = 0.7, color = "black") +
  labs(title = "Average Pageviews per Session", x = "Average Pageviews", y = "Number of Customers") +
  theme_minimal()

```


```{r}
raw_data <- raw_data %>%
  mutate(visitStartTime = as_datetime(visitStartTime))

# Extract hour of visit start time
raw_data <- raw_data %>%
  mutate(visit_hour = hour(visitStartTime))

# Plot visit start time frequency by hour
ggplot(raw_data, aes(x = visit_hour)) +
  geom_histogram(binwidth = 1, fill = "blue", alpha = 0.7, color = "black") +
  labs(title = "Visit Start Time Frequency", x = "Hour of the Day", y = "Frequency of Visits") +
  theme_minimal()
```
```{r}
visit_start_by_continent <- raw_data %>%
  group_by(continent, visit_hour) %>%
  summarise(frequency = n()) %>%
  ungroup()

# Create separate plots for each continent
continents <- unique(visit_start_by_continent$continent)

# Loop through each continent and create individual plots
for (continent in continents) {
  continent_data <- visit_start_by_continent %>%
    filter(continent == !!continent)
  
  # Plot visit start time frequency for the specific continent
  plot <- ggplot(continent_data, aes(x = visit_hour, y = frequency)) +
    geom_bar(stat = "identity", fill = "blue", alpha = 0.7, color = "black") +
    labs(title = paste("Visit Start Time Frequency -", continent), 
         x = "Hour of the Day", 
         y = "Frequency of Visits") +
    theme_minimal()
  
  # Print the plot
  print(plot)
}

```






